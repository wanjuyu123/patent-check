# **IPC/CPC Automatic Inference and Validation Tool (IPC/CPC è‡ªåŠ¨æ¨æ–­ä¸éªŒè¯å·¥å…·)**

This project provides a robust, end-to-end solution for automatically inferring IPC/CPC classification codes for patents using Large Language Models (LLMs) like GPT-4o. It then validates the AI-generated codes against a local, expert-defined mapping to evaluate the model's accuracy.

æœ¬é¡¹ç›®æä¾›äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼Œå¦‚ GPT-4oï¼‰ä¸ºä¸“åˆ©è‡ªåŠ¨æ¨æ–­ IPC/CPC åˆ†ç±»å·ï¼Œå¹¶å¯¹ç…§æœ¬åœ°çš„ä¸“å®¶çŸ¥è¯†åº“å¯¹æ¨æ–­ç»“æœè¿›è¡ŒéªŒè¯å’Œè¯„ä¼°ã€‚

## **âœ¨ Features (ä¸»è¦ç‰¹æ€§)**

* **ğŸ¤– LLM-based Inference**: Leverages the power of models like GPT-4o to analyze patent titles and abstracts for accurate code inference.  
* **âœ”ï¸ Local Validation**: Compares LLM results against a local "ground truth" mapping to quantitatively measure performance.  
* **â–¶ï¸ Resumable Execution**: Uses checkpoints to save progress, allowing you to resume interrupted jobs without starting over.  
* **âš¡ API Call Caching**: Caches every API request payload and its response, avoiding redundant calls and saving time and money on subsequent runs.  
* **âš™ï¸ Auto-Batching**: Dynamically adjusts the number of patents sent per API call to maximize throughput while respecting the model's context window limits.  
* **ğŸ”§ Highly Configurable**: Almost all parameters, including file paths, model names, and validation thresholds, can be configured via command-line arguments.

## **ğŸš€ Getting Started (å¿«é€Ÿå¼€å§‹)**

### **Prerequisites (ç¯å¢ƒè¦æ±‚)**

* Python 3.8+  
* Git

### **Installation (å®‰è£…æ­¥éª¤)**

1. **Clone the repository (å…‹éš†ä»£ç åº“):**  
   git clone \<your-repository-url\>  
   cd \<your-repository-name\>

2. **Create and activate a virtual environment (åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ):**  
   \# For macOS/Linux  
   python3 \-m venv venv  
   source venv/bin/activate

   \# For Windows  
   python \-m venv venv  
   .\\venv\\Scripts\\activate

3. **Install dependencies (å®‰è£…ä¾èµ–)**

### **Project Structure (é¡¹ç›®ç»“æ„)**

Your project should be organized with the following directory structure:

project-root/  
â”œâ”€â”€ .gitignore  
â”œâ”€â”€ mappings/  
â”‚   â””â”€â”€ Sensing.xlsx              \# Example mapping file for a domain  
â”œâ”€â”€ patents/  
â”‚   â””â”€â”€ Sensing/  
â”‚       â””â”€â”€ Radar\_Technology.csv    \# Example patent data for a technology  
â”œâ”€â”€ outputs/                        \# Generated output will be stored here (auto-created)  
â”œâ”€â”€ .env  
â”œâ”€â”€ .env.example  
â”œâ”€â”€ run.py  
â””â”€â”€ README.md

### **Configuration (é…ç½®)**

The script requires an OpenAI API key to function.

1. Create the environment file:  
   Copy the example file .env.example to a new file named .env. This file is listed in .gitignore and will not be committed to the repository.  
   cp .env.example .env

2. Add your API Key:  
   Open the .env file and add your OpenAI API key:  
   OPENAI\_API\_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

## **ğŸ’» Usage (å¦‚ä½•è¿è¡Œ)**

You can run the script from the command line.

Basic execution (ä½¿ç”¨é»˜è®¤å‚æ•°è¿è¡Œ):  
This command will use the default settings specified in run.py (e.g., directories, model).  
python run.py

Execution with custom arguments (ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°è¿è¡Œ):  
You can override the default settings using command-line flags.  
python run.py \--model gpt-4o \--auto-batch \--patents-dir /path/to/your/patents

### **Key Command-Line Arguments (ä¸»è¦å‘½ä»¤è¡Œå‚æ•°)**

| Argument | Description | Default Value |
| :---- | :---- | :---- |
| \--patents-dir | Directory containing the patent data, organized in domain subfolders. | patents |
| \--mappings-dir | Directory containing the expert mapping files (Excel/CSV). | mappings |
| \--outputs-dir | Directory where all results, caches, and state files will be saved. | outputs |
| \--model | The name of the OpenAI model to use for inference. | gpt-4o |
| \--auto-batch | If enabled, automatically calculates the optimal batch size. | False (disabled) |
| \--batch-size | Manually set the number of patents per API call (ignored if \--auto-batch). | 30 |
| \--tau-strong | The minimum A+B match rate to be considered "supported". | 0.35 |
| \--tau-min | The minimum A+B match rate to be considered "partially\_supported". | 0.15 |

## **ğŸ“Š Output (ç»“æœè¾“å‡º)**

The script generates all output in the outputs/ directory:

* outputs/raw/: Stores the raw JSON responses from every API call and cache files.  
* outputs/summary/: Contains a detailed CSV report for each individual technology subclass.  
* outputs/state/: Holds the checkpoints.json file for resuming execution.  
* outputs/summary\_all.csv: A final, consolidated report summarizing the results for all processed technologies.

## **ğŸ“„ License (è®¸å¯è¯)**

This project is licensed under the MIT License. See the LICENSE file for details.